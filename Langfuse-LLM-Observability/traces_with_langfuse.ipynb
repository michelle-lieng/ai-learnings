{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2bf6382",
   "metadata": {},
   "source": [
    "## AI System Observability with Langfuse\n",
    "\n",
    "First I created an account + organisation with langfuse in the cloud (OPTIONAL: Langfuse is open source and can be self-hosted using Docker) and saved my keys in .env.\n",
    "\n",
    "Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "\n",
    "I am using framework semantic kernel for this lesson.\n",
    "\n",
    "\"What is Semantic Kernel? Semantic Kernel (GitHub) is a powerful open-source SDK from Microsoft. It facilitates the combination of LLMs with popular programming languages like C#, Python, and Java. Semantic Kernel empowers developers to build sophisticated AI applications by seamlessly integrating AI services, data sources, and custom logic, accelerating the delivery of enterprise-grade AI solutions.\n",
    "\n",
    "What is Langfuse? Langfuse is an open-source platform dedicated to LLM observability. It offers robust tracing and monitoring capabilities tailored for AI applications. Langfuse helps developers debug, analyze, and optimize their AI systems by providing detailed insights and integrating with a wide array of tools and frameworks through native integrations, OpenTelemetry, and dedicated SDKs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bdd0c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langfuse in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: openlit in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.35.1)\n",
      "Requirement already satisfied: semantic-kernel in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.35.3)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langfuse) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langfuse) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langfuse) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langfuse) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langfuse) (1.37.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langfuse) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langfuse) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langfuse) (2.32.4)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langfuse) (1.17.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0,>=0.15.4->langfuse) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0,>=0.15.4->langfuse) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0,>=0.15.4->langfuse) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.16.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse) (8.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse) (4.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse) (1.37.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse) (5.29.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse) (0.58b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langfuse) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langfuse) (2.4.0)\n",
      "Requirement already satisfied: anthropic<1.0.0,>=0.42.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.67.0)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (1.40.33)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.34.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (1.40.33)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.15 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.3.27)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.1.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (1.107.2)\n",
      "Requirement already satisfied: openai-agents>=0.0.3 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.3.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp<2.0.0,>=1.30.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-aiohttp-client<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-django<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-falcon<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-flask<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-httpx<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-pyramid<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-requests<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-starlette<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-tornado<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-urllib<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-urllib3<1.0.0,>=0.52b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.58b0)\n",
      "Requirement already satisfied: schedule<2.0.0,>=1.2.2 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (1.2.2)\n",
      "Requirement already satisfied: xmltodict<1.0.0,>=0.13.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openlit) (0.15.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic<1.0.0,>=0.42.0->openlit) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic<1.0.0,>=0.42.0->openlit) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anthropic<1.0.0,>=0.42.0->openlit) (1.3.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3<2.0.0,>=1.34.0->openlit) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3<2.0.0,>=1.34.0->openlit) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from botocore<2.0.0,>=1.34.0->openlit) (2.9.0.post0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.4.0,>=0.3.15->openlit) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.4.0,>=0.3.15->openlit) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.4.0,>=0.3.15->openlit) (0.4.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.4.0,>=0.3.15->openlit) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.4.0,>=0.3.15->openlit) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.15->openlit) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.15->openlit) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.15->openlit) (3.0.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.1.1->openlit) (4.67.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.37.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp<2.0.0,>=1.30.0->openlit) (1.37.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.37.0->opentelemetry-exporter-otlp<2.0.0,>=1.30.0->openlit) (1.73.0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.58b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-instrumentation-aiohttp-client<1.0.0,>=0.52b0->openlit) (0.58b0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-instrumentation-asgi<1.0.0,>=0.52b0->openlit) (3.9.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-wsgi==0.58b0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-instrumentation-django<1.0.0,>=0.52b0->openlit) (0.58b0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.34.0->openlit) (1.17.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.3.15->openlit) (3.2.4)\n",
      "Requirement already satisfied: azure-ai-projects>=1.0.0b12 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.1.0b2)\n",
      "Requirement already satisfied: azure-ai-agents>=1.1.0b4 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.2.0b2)\n",
      "Requirement already satisfied: aiohttp~=3.8 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (3.12.15)\n",
      "Requirement already satisfied: cloudevents~=1.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.12.0)\n",
      "Requirement already satisfied: pydantic-settings~=2.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: defusedxml~=0.7 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: azure-identity>=1.13 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.24.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (2.3.0)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (0.19.5)\n",
      "Requirement already satisfied: websockets<16,>=13 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (15.0.1)\n",
      "Requirement already satisfied: aiortc>=1.9.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.13.0)\n",
      "Requirement already satisfied: prance<25.4.9,>=23.6.21 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (25.4.8.0)\n",
      "Requirement already satisfied: pybars4~=0.9 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (0.9.13)\n",
      "Requirement already satisfied: jinja2~=3.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (3.1.6)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in c:\\users\\michelle\\appdata\\roaming\\python\\python311\\site-packages (from semantic-kernel) (1.6.0)\n",
      "Requirement already satisfied: scipy>=1.15.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel) (1.16.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.20.1)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cloudevents~=1.0->semantic-kernel) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2~=3.1->semantic-kernel) (3.0.2)\n",
      "Requirement already satisfied: isodate in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.25.1)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.3.4)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.7.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: parse in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (1.20.2)\n",
      "Requirement already satisfied: werkzeug<3.1.2 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (3.1.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.27.0)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (0.4.4)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel) (1.11.0)\n",
      "Requirement already satisfied: chardet>=5.2 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prance<25.4.9,>=23.6.21->semantic-kernel) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.18.10 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prance<25.4.9,>=23.6.21->semantic-kernel) (0.18.15)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pybars4~=0.9->semantic-kernel) (0.5.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings~=2.0->semantic-kernel) (1.1.0)\n",
      "Requirement already satisfied: aioice<1.0.0,>=0.10.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (0.10.1)\n",
      "Requirement already satisfied: av<15.0.0,>=14.0.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (14.4.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=44.0.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (45.0.4)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (1.7.1)\n",
      "Requirement already satisfied: pyee>=13.0.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (13.0.0)\n",
      "Requirement already satisfied: pylibsrtp>=0.10.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (0.12.0)\n",
      "Requirement already satisfied: pyopenssl>=25.0.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiortc>=1.9.0->semantic-kernel) (25.1.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel) (2.7.0)\n",
      "Requirement already satisfied: ifaddr>=0.2.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel) (0.2.0)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-agents>=1.1.0b4->semantic-kernel) (1.35.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.15.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-ai-projects>=1.0.0b12->semantic-kernel) (12.26.0)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-identity>=1.13->semantic-kernel) (1.33.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-identity>=1.13->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0.0->aiortc>=1.9.0->semantic-kernel) (2.22)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.15->openlit) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.15->openlit) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.15->openlit) (0.24.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity>=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: griffe<2,>=1.5.6 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai-agents>=0.0.3->openlit) (1.14.0)\n",
      "Requirement already satisfied: mcp<2,>=1.11.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai-agents>=0.0.3->openlit) (1.14.0)\n",
      "Requirement already satisfied: types-requests<3,>=2.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai-agents>=0.0.3->openlit) (2.32.4.20250913)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from griffe<2,>=1.5.6->openai-agents>=0.0.3->openlit) (0.4.6)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.3->openlit) (0.4.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.3->openlit) (0.0.20)\n",
      "Requirement already satisfied: pywin32>=310 in c:\\users\\michelle\\appdata\\roaming\\python\\python311\\site-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.3->openlit) (311)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.3->openlit) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.3->openlit) (0.46.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents>=0.0.3->openlit) (0.34.3)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ruamel.yaml>=0.18.10->prance<25.4.9,>=23.6.21->semantic-kernel) (0.2.12)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\michelle\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents>=0.0.3->openlit) (8.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langfuse openlit semantic-kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa206c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGFUSE_HOST: https://cloud.langfuse.com\n",
      "LANGFUSE_PUBLIC_KEY: pk-lf-c2801e72-06d8-4d9a-bbb2-da9168b7cfe1\n",
      "LANGFUSE_SECRET_KEY: sk-lf-4c8d2ed8-6b98-48df-a66f-84edda97efbb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"LANGFUSE_HOST:\", os.getenv(\"LANGFUSE_HOST\"))\n",
    "print(\"LANGFUSE_PUBLIC_KEY:\", os.getenv(\"LANGFUSE_PUBLIC_KEY\"))\n",
    "print(\"LANGFUSE_SECRET_KEY:\", os.getenv(\"LANGFUSE_SECRET_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51af4c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse client is authenticated and ready!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langfuse import get_client\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "# Saved all the keys in .env\n",
    "\n",
    "langfuse = get_client()\n",
    "\n",
    "# from langfuse import Langfuse\n",
    "\n",
    "# langfuse = Langfuse(\n",
    "#     public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "#     secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "#     host=\"https://cloud.langfuse.com\"  # or your self-hosted URL\n",
    "# )\n",
    " \n",
    "# Verify connection\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "    print(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1454443",
   "metadata": {},
   "source": [
    "Now, we initialize the OpenLit instrumentation SDK. OpenLit automatically instruments Semantic Kernel and exports OpenTelemetry (OTel) spans to Langfuse.\n",
    "\n",
    "Here is more explanation:\n",
    "1. We have our agent running using semantic kernel framework.\n",
    "Semantic Kernel (SK) = AI orchestration framework (similar to Langchain).\n",
    "2. When we initialize the OpenLit SDK it hooks into semantic kernel. \n",
    "OpenLit = SDK that auto-instruments your AI app (it's like a wrapper around your AI app that captures traces without manual logging). \n",
    "3. Every LM/tool call becomes an OTel spans.\n",
    "OpenTelemetry (OTel) is an industry standard for tracing, metrics and logging. A span = 1 unit of work. E.g. a single LLM completion = 1 span. An agent workflow with 5 tool calls = root span (agent) + 5 child spans (tool calls). Spans contain metadata like prompt, model used, latency, costt (tokens, $$ if tracked), response.\n",
    "4. These spans get exported to Langfuse.\n",
    "Langfuse = this is an observability + evaluation platform for LLM apps --> where spans get stored/visualized â†’ dashboards, trace trees, metrics, evals. This is where you can visualize and evaluate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231cd705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michelle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758194409986529800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 1936,\n",
      "                                                \"time_unix_nano\": 1758194388287112000,\n",
      "                                                \"span_id\": 3631019496371042222,\n",
      "                                                \"trace_id\": 152108595109406751309011362409105896336\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194409986529800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 45.000076,\n",
      "                                                \"time_unix_nano\": 1758194388290124000,\n",
      "                                                \"span_id\": 13666311020481293966,\n",
      "                                                \"trace_id\": 152108595109406751309011362409105896336\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194409986529800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 1.9423270225524902,\n",
      "                                                \"time_unix_nano\": 1758194388290124000,\n",
      "                                                \"span_id\": 13666311020481293966,\n",
      "                                                \"trace_id\": 152108595109406751309011362409105896336\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194409986529800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 0,\n",
      "                                                \"time_unix_nano\": 1758194388290124000,\n",
      "                                                \"span_id\": 13666311020481293966,\n",
      "                                                \"trace_id\": 152108595109406751309011362409105896336\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194409986529800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 1.9423270225524902,\n",
      "                                                \"time_unix_nano\": 1758194388290124000,\n",
      "                                                \"span_id\": 13666311020481293966,\n",
      "                                                \"trace_id\": 152108595109406751309011362409105896336\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194409986529800,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 1,\n",
      "                                                \"time_unix_nano\": 1758194388290124000,\n",
      "                                                \"span_id\": 13666311020481293966,\n",
      "                                                \"trace_id\": 152108595109406751309011362409105896336\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194409986529800,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 6.4e-05,\n",
      "                                                \"time_unix_nano\": 1758194386324150600,\n",
      "                                                \"span_id\": 4766977972418127573,\n",
      "                                                \"trace_id\": 37210595605952202876048237464255262968\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194409986529800,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 45,\n",
      "                                                \"time_unix_nano\": 1758194388290124000,\n",
      "                                                \"span_id\": 13666311020481293966,\n",
      "                                                \"trace_id\": 152108595109406751309011362409105896336\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194409986529800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 17,\n",
      "                                                \"time_unix_nano\": 1758194388290124000,\n",
      "                                                \"span_id\": 13666311020481293966,\n",
      "                                                \"trace_id\": 152108595109406751309011362409105896336\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758194409986529800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 1.9453279000008479,\n",
      "                                                \"time_unix_nano\": 1758194388291122800,\n",
      "                                                \"span_id\": 8840100529783236758,\n",
      "                                                \"trace_id\": 152108595109406751309011362409105896336\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758194470009074400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194470009074400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194470009074400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194470009074400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194470009074400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194470009074400,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194470009074400,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194470009074400,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194470009074400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758194470009074400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758194530035106600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194530035106600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194530035106600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194530035106600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194530035106600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194530035106600,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194530035106600,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194530035106600,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194530035106600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758194530035106600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758194590048417600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194590048417600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194590048417600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194590048417600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194590048417600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194590048417600,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194590048417600,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194590048417600,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194590048417600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758194590048417600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758194650073955300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194650073955300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194650073955300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194650073955300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194650073955300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194650073955300,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194650073955300,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194650073955300,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194650073955300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758194650073955300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758194710118596900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194710118596900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194710118596900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194710118596900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194710118596900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194710118596900,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194710118596900,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194710118596900,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194710118596900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758194710118596900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758194770166668500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194770166668500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194770166668500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194770166668500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194770166668500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194770166668500,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194770166668500,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194770166668500,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194770166668500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758194770166668500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758194830191871100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194830191871100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194830191871100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194830191871100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194830191871100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194830191871100,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194830191871100,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194830191871100,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194830191871100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758194830191871100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758194890212631400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194890212631400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194890212631400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194890212631400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194890212631400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194890212631400,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194890212631400,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194890212631400,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194890212631400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758194890212631400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758194950237791700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194950237791700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194950237791700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194950237791700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194950237791700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194950237791700,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194950237791700,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194950237791700,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758194950237791700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758194950237791700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195010263627400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195010263627400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195010263627400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195010263627400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195010263627400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195010263627400,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195010263627400,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195010263627400,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195010263627400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195010263627400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195070279407700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195070279407700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195070279407700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195070279407700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195070279407700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195070279407700,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195070279407700,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195070279407700,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195070279407700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195070279407700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195130310530600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195130310530600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195130310530600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195130310530600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195130310530600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195130310530600,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195130310530600,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195130310530600,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195130310530600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195130310530600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195190332978900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195190332978900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195190332978900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195190332978900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195190332978900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195190332978900,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195190332978900,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195190332978900,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195190332978900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195190332978900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195250344405800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195250344405800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195250344405800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195250344405800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195250344405800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195250344405800,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195250344405800,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195250344405800,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195250344405800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195250344405800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195310356666600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195310356666600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195310356666600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195310356666600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195310356666600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195310356666600,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195310356666600,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195310356666600,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195310356666600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195310356666600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195370374641500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195370374641500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195370374641500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195370374641500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195370374641500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195370374641500,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195370374641500,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195370374641500,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195370374641500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195370374641500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195430393954400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195430393954400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195430393954400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195430393954400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195430393954400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195430393954400,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195430393954400,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195430393954400,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195430393954400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195430393954400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195490412067700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195490412067700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195490412067700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195490412067700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195490412067700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195490412067700,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195490412067700,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195490412067700,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195490412067700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195490412067700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195550434754700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195550434754700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195550434754700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195550434754700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195550434754700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195550434754700,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195550434754700,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195550434754700,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195550434754700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195550434754700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195610446203000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195610446203000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195610446203000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195610446203000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195610446203000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195610446203000,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195610446203000,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195610446203000,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195610446203000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195610446203000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195670461233400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195670461233400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195670461233400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195670461233400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195670461233400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195670461233400,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195670461233400,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195670461233400,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195670461233400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195670461233400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195730470124400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195730470124400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195730470124400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195730470124400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195730470124400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195730470124400,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195730470124400,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195730470124400,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195730470124400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195730470124400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195790491277800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195790491277800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195790491277800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195790491277800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195790491277800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195790491277800,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195790491277800,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195790491277800,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195790491277800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195790491277800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195850505899800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195850505899800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195850505899800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195850505899800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195850505899800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195850505899800,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195850505899800,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195850505899800,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195850505899800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195850505899800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195910525800600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195910525800600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195910525800600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195910525800600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195910525800600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195910525800600,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195910525800600,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195910525800600,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195910525800600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195910525800600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758195970550072100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195970550072100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195970550072100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195970550072100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195970550072100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195970550072100,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195970550072100,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195970550072100,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758195970550072100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758195970550072100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196030564509000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196030564509000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196030564509000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196030564509000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196030564509000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196030564509000,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196030564509000,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196030564509000,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196030564509000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196030564509000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196090589599300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196090589599300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196090589599300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196090589599300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196090589599300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196090589599300,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196090589599300,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196090589599300,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196090589599300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196090589599300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196150604467400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196150604467400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196150604467400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196150604467400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196150604467400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196150604467400,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196150604467400,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196150604467400,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196150604467400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196150604467400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196210627267500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196210627267500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196210627267500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196210627267500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196210627267500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196210627267500,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196210627267500,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196210627267500,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196210627267500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196210627267500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196270652629000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196270652629000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196270652629000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196270652629000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196270652629000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196270652629000,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196270652629000,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196270652629000,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196270652629000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196270652629000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196330661401300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196330661401300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196330661401300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196330661401300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196330661401300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196330661401300,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196330661401300,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196330661401300,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196330661401300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196330661401300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196390677551700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196390677551700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196390677551700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196390677551700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196390677551700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196390677551700,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196390677551700,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196390677551700,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196390677551700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196390677551700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196450697890700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196450697890700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196450697890700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196450697890700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196450697890700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196450697890700,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196450697890700,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196450697890700,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196450697890700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196450697890700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196510710739000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196510710739000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196510710739000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196510710739000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196510710739000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196510710739000,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196510710739000,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196510710739000,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196510710739000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196510710739000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196570725659700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196570725659700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196570725659700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196570725659700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196570725659700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196570725659700,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196570725659700,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196570725659700,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196570725659700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196570725659700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196630748786800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196630748786800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196630748786800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196630748786800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196630748786800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196630748786800,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196630748786800,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196630748786800,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196630748786800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196630748786800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196690772134500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196690772134500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196690772134500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196690772134500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196690772134500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196690772134500,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196690772134500,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196690772134500,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196690772134500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196690772134500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196750798197800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196750798197800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196750798197800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196750798197800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196750798197800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196750798197800,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196750798197800,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196750798197800,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196750798197800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196750798197800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196810812413900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196810812413900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196810812413900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196810812413900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196810812413900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196810812413900,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196810812413900,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196810812413900,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196810812413900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196810812413900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196870822821200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196870822821200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196870822821200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196870822821200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196870822821200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196870822821200,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196870822821200,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196870822821200,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196870822821200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196870822821200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196930857001300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196930857001300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196930857001300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196930857001300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196930857001300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196930857001300,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196930857001300,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196930857001300,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196930857001300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196930857001300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758196990882988600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196990882988600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196990882988600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196990882988600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196990882988600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196990882988600,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196990882988600,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196990882988600,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758196990882988600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758196990882988600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197050894660500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197050894660500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197050894660500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197050894660500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197050894660500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197050894660500,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197050894660500,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197050894660500,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197050894660500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197050894660500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197110902305600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197110902305600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197110902305600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197110902305600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197110902305600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197110902305600,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197110902305600,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197110902305600,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197110902305600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197110902305600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197170916195400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197170916195400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197170916195400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197170916195400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197170916195400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197170916195400,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197170916195400,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197170916195400,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197170916195400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197170916195400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197230936413100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197230936413100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197230936413100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197230936413100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197230936413100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197230936413100,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197230936413100,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197230936413100,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197230936413100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197230936413100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197290985271300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197290985271300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197290985271300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197290985271300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197290985271300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197290985271300,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197290985271300,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197290985271300,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197290985271300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197290985271300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197351033966700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197351033966700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197351033966700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197351033966700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197351033966700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197351033966700,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197351033966700,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197351033966700,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197351033966700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197351033966700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197411045826100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197411045826100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197411045826100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197411045826100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197411045826100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197411045826100,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197411045826100,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197411045826100,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197411045826100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197411045826100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197471073144200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197471073144200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197471073144200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197471073144200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197471073144200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197471073144200,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197471073144200,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197471073144200,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197471073144200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197471073144200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197531089509800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197531089509800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197531089509800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197531089509800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197531089509800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197531089509800,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197531089509800,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197531089509800,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197531089509800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197531089509800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197591108831800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197591108831800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197591108831800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197591108831800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197591108831800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197591108831800,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197591108831800,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197591108831800,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197591108831800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197591108831800,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197651117513300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197651117513300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197651117513300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197651117513300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197651117513300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197651117513300,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197651117513300,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197651117513300,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197651117513300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197651117513300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197711147187300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197711147187300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197711147187300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197711147187300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197711147187300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197711147187300,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197711147187300,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197711147187300,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197711147187300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197711147187300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197771207301700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197771207301700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197771207301700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197771207301700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197771207301700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197771207301700,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197771207301700,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197771207301700,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197771207301700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197771207301700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197831309002900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197831309002900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197831309002900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197831309002900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197831309002900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197831309002900,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197831309002900,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197831309002900,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197831309002900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197831309002900,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197891338223200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197891338223200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197891338223200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197891338223200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197891338223200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197891338223200,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197891338223200,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197891338223200,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197891338223200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197891338223200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758197951361071200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197951361071200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197951361071200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197951361071200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197951361071200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197951361071200,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197951361071200,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197951361071200,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758197951361071200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758197951361071200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198011383624100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198011383624100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198011383624100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198011383624100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198011383624100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198011383624100,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198011383624100,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198011383624100,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198011383624100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198011383624100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198071411681200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198071411681200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198071411681200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198071411681200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198071411681200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198071411681200,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198071411681200,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198071411681200,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198071411681200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198071411681200,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198131429004400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198131429004400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198131429004400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198131429004400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198131429004400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198131429004400,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198131429004400,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198131429004400,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198131429004400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198131429004400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198191450774400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198191450774400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198191450774400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198191450774400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198191450774400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198191450774400,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198191450774400,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198191450774400,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198191450774400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198191450774400,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198251463317100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198251463317100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198251463317100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198251463317100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198251463317100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198251463317100,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198251463317100,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198251463317100,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198251463317100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198251463317100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198311485282100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198311485282100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198311485282100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198311485282100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198311485282100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198311485282100,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198311485282100,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198311485282100,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198311485282100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198311485282100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198371498709500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198371498709500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198371498709500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198371498709500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198371498709500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198371498709500,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198371498709500,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198371498709500,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198371498709500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198371498709500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198431524277300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198431524277300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198431524277300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198431524277300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198431524277300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198431524277300,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198431524277300,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198431524277300,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198431524277300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198431524277300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198491600327700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198491600327700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198491600327700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198491600327700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198491600327700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198491600327700,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198491600327700,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198491600327700,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198491600327700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198491600327700,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198551669704100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198551669704100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198551669704100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198551669704100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198551669704100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198551669704100,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198551669704100,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198551669704100,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198551669704100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198551669704100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198611700642500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198611700642500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198611700642500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198611700642500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198611700642500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198611700642500,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198611700642500,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198611700642500,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198611700642500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198611700642500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198671727241600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198671727241600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198671727241600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198671727241600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198671727241600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198671727241600,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198671727241600,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198671727241600,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198671727241600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198671727241600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198731763459000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198731763459000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198731763459000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198731763459000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198731763459000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198731763459000,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198731763459000,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198731763459000,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198731763459000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198731763459000,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198791780266500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198791780266500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198791780266500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198791780266500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198791780266500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198791780266500,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198791780266500,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198791780266500,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198791780266500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198791780266500,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198851796966300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198851796966300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198851796966300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198851796966300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198851796966300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198851796966300,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198851796966300,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198851796966300,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198851796966300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198851796966300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"openlit\",\n",
      "                    \"telemetry.sdk.version\": \"1.37.0\",\n",
      "                    \"service.name\": \"default\",\n",
      "                    \"deployment.environment\": \"default\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"opentelemetry.instrumentation.httpx\",\n",
      "                        \"version\": \"0.58b0\",\n",
      "                        \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"http.client.duration\",\n",
      "                            \"description\": \"measures the duration of the outbound HTTP request\",\n",
      "                            \"unit\": \"ms\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"http.method\": \"POST\",\n",
      "                                            \"http.scheme\": \"https\",\n",
      "                                            \"http.status_code\": 200\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386299791700,\n",
      "                                        \"time_unix_nano\": 1758198911820837100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4021,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1936,\n",
      "                                        \"max\": 2085,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"https://opentelemetry.io/schemas/1.11.0\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"openlit.otel.metrics\",\n",
      "                        \"version\": \"0.1.0\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Measures number of input and output tokens used\",\n",
      "                            \"unit\": \"{token}\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198911820837100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 82.00014,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 37.000064,\n",
      "                                        \"max\": 45.000076,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"GenAI operation duration\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198911820837100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_per_output_token\",\n",
      "                            \"description\": \"Time per output token generated after the first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198911820837100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 0,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.025,\n",
      "                                            0.05,\n",
      "                                            0.075,\n",
      "                                            0.1,\n",
      "                                            0.15,\n",
      "                                            0.2,\n",
      "                                            0.3,\n",
      "                                            0.4,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5\n",
      "                                        ],\n",
      "                                        \"min\": 0,\n",
      "                                        \"max\": 0,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.server.time_to_first_token\",\n",
      "                            \"description\": \"Time to generate first token for successful responses\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198911820837100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.071183919906616,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.001,\n",
      "                                            0.005,\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.06,\n",
      "                                            0.08,\n",
      "                                            0.1,\n",
      "                                            0.25,\n",
      "                                            0.5,\n",
      "                                            0.75,\n",
      "                                            1.0,\n",
      "                                            2.5,\n",
      "                                            5.0,\n",
      "                                            7.5,\n",
      "                                            10.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9423270225524902,\n",
      "                                        \"max\": 2.128856897354126,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.total.requests\",\n",
      "                            \"description\": \"Number of requests to GenAI\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198911820837100,\n",
      "                                        \"value\": 2,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.output_tokens\",\n",
      "                            \"description\": \"Number of completion tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198911820837100,\n",
      "                                        \"value\": 0.00014,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.input_tokens\",\n",
      "                            \"description\": \"Number of prompt tokens processed.\",\n",
      "                            \"unit\": \"1\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198911820837100,\n",
      "                                        \"value\": 82,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2,\n",
      "                                \"is_monotonic\": true\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.usage.cost\",\n",
      "                            \"description\": \"The distribution of GenAI request costs.\",\n",
      "                            \"unit\": \"USD\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"telemetry.sdk.name\": \"openlit\",\n",
      "                                            \"service.name\": \"default\",\n",
      "                                            \"deployment.environment\": \"default\",\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.system\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-3.5-turbo\",\n",
      "                                            \"server.address\": \"api.openai.com\",\n",
      "                                            \"server.port\": 443,\n",
      "                                            \"gen_ai.response.model\": \"gpt-3.5-turbo-0125\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386324150600,\n",
      "                                        \"time_unix_nano\": 1758198911820837100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 34,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 17,\n",
      "                                        \"max\": 17,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                },\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"semantic_kernel.functions.kernel_function\",\n",
      "                        \"version\": null,\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"semantic_kernel.function.invocation.duration\",\n",
      "                            \"description\": \"Measures the duration of a function's execution\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"semantic_kernel.function.name\": \"summarizePlugin-summarizeFunc\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1758194386325673900,\n",
      "                                        \"time_unix_nano\": 1758198911820837100,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.107379599998239,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.0,\n",
      "                                            5.0,\n",
      "                                            10.0,\n",
      "                                            25.0,\n",
      "                                            50.0,\n",
      "                                            75.0,\n",
      "                                            100.0,\n",
      "                                            250.0,\n",
      "                                            500.0,\n",
      "                                            750.0,\n",
      "                                            1000.0,\n",
      "                                            2500.0,\n",
      "                                            5000.0,\n",
      "                                            7500.0,\n",
      "                                            10000.0\n",
      "                                        ],\n",
      "                                        \"min\": 1.9453279000008479,\n",
      "                                        \"max\": 2.1620516999973916,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openlit\n",
    " \n",
    "# Initialize OpenLIT instrumentation. The disable_batch flag is set to true to process traces immediately. Also set the langfuse tracer to use the langfuse tracer.\n",
    "openlit.init(tracer=langfuse._otel_tracer, disable_batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae98cb41",
   "metadata": {},
   "source": [
    "Do a Basic Semantic Kernel Application\n",
    "Letâ€™s create a straightforward Semantic Kernel application. In this example, an Assistant agent will answer a userâ€™s question. This will serve as the foundation for demonstrating Langfuse tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43ab9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.prompt_template import InputVariable, PromptTemplateConfig\n",
    " \n",
    "kernel = Kernel()\n",
    " \n",
    "kernel.add_service(\n",
    "    OpenAIChatCompletion(api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "                         ai_model_id=\"gpt-3.5-turbo\"),\n",
    ")\n",
    " \n",
    "prompt = \"\"\"{{$input}}\n",
    "Answer the question above.\n",
    "\"\"\"\n",
    " \n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"summarize\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The user input\", is_required=True),\n",
    "    ]\n",
    ")\n",
    " \n",
    "summarize = kernel.add_function(\n",
    "    function_name=\"summarizeFunc\",\n",
    "    plugin_name=\"summarizePlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04024e32",
   "metadata": {},
   "source": [
    "Let's run the SK application. OpenLit will automatically capture this interaction and send the trace data to Langfuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb93c33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse is a language translation tool that provides quick and accurate translations between different languages. It can help users communicate with people who speak different languages and understand written content in a foreign language.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What is Langfuse?\"\n",
    " \n",
    "summary = await kernel.invoke(summarize, input=input_text)\n",
    " \n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1794891b",
   "metadata": {},
   "source": [
    "View traces in Langfuse!\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"..\\assets\\langfuse\\langfuse-1st-trace.png\" alt=\"Langfuse 1st trace\" width=\"600\"/>\n",
    "</p>\n",
    "\n",
    "You can use this integration together with the Langfuse Python SDK to add additional attributes to the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca6d3b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dog is a domesticated carnivorous mammal that has been bred and kept as a pet for thousands of years. They are known for their loyalty, companionship, and ability to form strong bonds with their human owners.\n"
     ]
    }
   ],
   "source": [
    "from langfuse import observe, get_client\n",
    " \n",
    "langfuse = get_client()\n",
    " \n",
    "@observe()\n",
    "async def semantic_kernel_function(input):\n",
    "    output = await kernel.invoke(summarize, input=input)\n",
    "\n",
    "    langfuse.update_current_trace(\n",
    "        input=input,\n",
    "        output=output,\n",
    "        user_id=\"user_123\",\n",
    "        session_id=\"session_abc\",\n",
    "        tags=[\"agent\", \"my-trace\"],\n",
    "        metadata={\"email\": \"user@langfuse.com\"},\n",
    "        version=\"1.0.0\"\n",
    "    )\n",
    "\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = await semantic_kernel_function(\"What is a dog?\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
