{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6dbc6d",
   "metadata": {},
   "source": [
    "## OpenAI Agent SDK Demo\n",
    "\n",
    "Core concepts:\n",
    "- Agents: LLMs configured with instructions, tools, guardrails, and handoffs\n",
    "- Handoffs: A specialized tool call used by the Agents SDK for transferring control between agents\n",
    "- Guardrails: Configurable safety checks for input and output validation\n",
    "- Sessions: Automatic conversation history management across agent runs\n",
    "- Tracing: Built-in tracking of agent runs, allowing you to view, debug and optimize your workflows\n",
    "\n",
    "The agent loop:  \n",
    "When you call Runner.run(), we run a loop until we get a final output.\n",
    "\n",
    "We call the LLM, using the model and settings on the agent, and the message history.\n",
    "The LLM returns a response, which may include tool calls.\n",
    "If the response has a final output (see below for more on this), we return it and end the loop.\n",
    "If the response has a handoff, we set the agent to the new agent and go back to step 1.\n",
    "We process the tool calls (if any) and append the tool responses messages. Then we go to step 1.\n",
    "There is a max_turns parameter that you can use to limit the number of times the loop executes.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"..\\assets\\agent-sdk.png\" width=700px>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2185e04",
   "metadata": {},
   "source": [
    "#### View traces [here](https://platform.openai.com/logs?api=traces) on OpenAI's platform where they enable logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8756d044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-agents in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: griffe<2,>=1.5.6 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from openai-agents) (1.14.0)\n",
      "Requirement already satisfied: mcp<2,>=1.11.0 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from openai-agents) (1.14.1)\n",
      "Requirement already satisfied: openai<2,>=1.107.1 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from openai-agents) (1.108.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.10 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from openai-agents) (2.11.9)\n",
      "Requirement already satisfied: requests<3,>=2.0 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from openai-agents) (2.32.5)\n",
      "Requirement already satisfied: types-requests<3,>=2.0 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from openai-agents) (2.32.4.20250913)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.12.2 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from openai-agents) (4.15.0)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from griffe<2,>=1.5.6->openai-agents) (0.4.6)\n",
      "Requirement already satisfied: anyio>=4.5 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (4.10.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.4.1)\n",
      "Requirement already satisfied: httpx>=0.27.1 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.0.20)\n",
      "Requirement already satisfied: pywin32>=310 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (311)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.48.0)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.35.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from openai<2,>=1.107.1->openai-agents) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from openai<2,>=1.107.1->openai-agents) (0.11.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from openai<2,>=1.107.1->openai-agents) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from openai<2,>=1.107.1->openai-agents) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from pydantic<3,>=2.10->openai-agents) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from requests<3,>=2.0->openai-agents) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from requests<3,>=2.0->openai-agents) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from requests<3,>=2.0->openai-agents) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents) (1.1.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\michelle\\data-science\\ai-learnings\\.venv\\lib\\site-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents) (8.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938272dd",
   "metadata": {},
   "source": [
    "Note: this example isn't exactly an agent as it has no tool calls but this is just for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c22e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A **dog** is a domesticated mammal and a subspecies of the gray wolf, scientifically known as *Canis lupus familiaris*. Dogs have been companions to humans for thousands of years and are one of the most popular pets worldwide.\n",
      "\n",
      "**Key facts about dogs:**\n",
      "- **Species:** Canis lupus familiaris\n",
      "- **Family:** Canidae (the dog family, which also includes wolves, foxes, and other similar animals)\n",
      "- **Domestication:** Dogs were domesticated from wolves tens of thousands of years ago.\n",
      "- **Characteristics:** Most dogs have fur, a keen sense of smell, good hearing, and a relatively strong body. They come in a wide variety of breeds, sizes, shapes, and temperaments.\n",
      "- **Roles:** Dogs are used for many purposes, including companionship, hunting, herding, protection, service work (like guide dogs for the blind), and police or military work.\n",
      "\n",
      "Dogs are known for their loyalty, trainability, and ability to bond closely with humans.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# define the agents\n",
    "agent = Agent(name=\"Assistant\", \n",
    "              instructions=\"You are a helpful assistant\")\n",
    "\n",
    "# get the runner to loop\n",
    "result = await Runner.run(agent, \n",
    "                          \"What is a dog?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec21529e",
   "metadata": {},
   "source": [
    "### Handoffs example\n",
    "\n",
    "An agent is an AI model configured with instructions, tools, guardrails, handoffs and more.\n",
    "\n",
    "We strongly recommend passing instructions, which is the \"system prompt\" for the agent. In addition, you can pass handoff_description, which is a human-readable description of the agent, used when the agent is used inside tools/handoffs.\n",
    "\n",
    "Agents are generic on the context type. The context is a (mutable) object you create. It is passed to tool functions, handoffs, guardrails, etc.\n",
    "\n",
    "#### CAN ADD MAX TURNS!!!!!!!!!!! THIS LIMITS THE AMOUNT OF LOOPS WE DO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b66f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! Estoy muy bien, gracias. ¿Y tú? ¿En qué puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"Spanish agent\",\n",
    "    instructions=\"You only speak Spanish.\",\n",
    "    handoff_description=\"Specialized agent for speaking spanish\"\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"English agent\",\n",
    "    instructions=\"You only speak English\",\n",
    "    handoff_description=\"Specialized agent for speaking english\"\n",
    ")\n",
    "\n",
    "# could say this is the principle agent that handles the other \n",
    "# task agents as tool calls almost (agent handoff)\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[spanish_agent, english_agent],\n",
    ")\n",
    "\n",
    "result = await Runner.run(triage_agent, \n",
    "                          input=\"Hola, ¿cómo estás?\",\n",
    "                          max_turns=5   # limit conversation loop to 5 turns\n",
    "                        )\n",
    "# CAN ADD MAX TURNS!!!!!!!!!!! THIS LIMITS THE AMOUNT OF LOOPS WE DO\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8520e57b",
   "metadata": {},
   "source": [
    "Functions example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce777919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Tokyo is currently sunny. If you need more details like temperature or forecast, let me know!\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Hello world\",\n",
    "    instructions=\"You are a helpful agent.\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, input=\"What's the weather in Tokyo?\")\n",
    "print(result.final_output)\n",
    "# The weather in Tokyo is sunny."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf058f4",
   "metadata": {},
   "source": [
    "Sessions\n",
    "--------\n",
    "The Agents SDK provides built-in session memory to automatically maintain conversation history across multiple agent runs, eliminating the need to manually handle .to_input_list() between turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af4c8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Francisco.\n",
      "California.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, SQLiteSession\n",
    "\n",
    "# Create agent\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"Reply very concisely.\",\n",
    ")\n",
    "\n",
    "# Create a session instance\n",
    "session = SQLiteSession(\"conversation_123\")\n",
    "\n",
    "# First turn\n",
    "result = await Runner.run(\n",
    "    agent,\n",
    "    \"What city is the Golden Gate Bridge in?\",\n",
    "    session=session\n",
    ")\n",
    "print(result.final_output)  # \"San Francisco\"\n",
    "\n",
    "# Second turn - agent automatically remembers previous context\n",
    "result = await Runner.run(\n",
    "    agent,\n",
    "    \"What state is it in?\",\n",
    "    session=session\n",
    ")\n",
    "print(result.final_output)  # \"California\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc49bdef",
   "metadata": {},
   "source": [
    "Session options\n",
    "No memory (default): No session memory when session parameter is omitted\n",
    "session: Session = DatabaseSession(...): Use a Session instance to manage conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a60e6319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of the 2020 United States Census, the population of **San Francisco, California** was approximately **815,201** people. More recent estimates (as of 2023) put the population at around **808,000**.\n",
      "Could you please clarify what location or entity you’re referring to? For example, are you asking about the population of a specific country, city, or region? Let me know so I can give you the most accurate and up-to-date information!\n",
      "A **dog** is a domesticated mammal with the scientific name **Canis lupus familiaris**. Dogs are closely related to wolves and are believed to have been domesticated by humans more than 15,000 years ago. They are known for their loyalty, companionship, intelligence, and a wide range of breeds with different physical and behavioral traits.\n",
      "\n",
      "**Key facts about dogs:**\n",
      "- **Classification:** Mammal, in the family Canidae.\n",
      "- **Diet:** Omnivorous, but primarily carnivorous.\n",
      "- **Lifespan:** Varies by breed, typically 10-15 years.\n",
      "- **Roles:** Companion animal, working animal (such as guide dogs, police dogs, herding dogs, and search-and-rescue dogs).\n",
      "- **Senses:** Highly developed sense of smell and hearing.\n",
      "- **Communication:** Use barks, growls, whines, body language, and facial expressions to communicate.\n",
      "\n",
      "Dogs are one of the most popular pets in the world and have been bred for various purposes, leading to hundreds of recognized breeds, ranging from tiny Chihuahuas to large Great Danes.\n",
      "\n",
      "Would you like information on dog breeds, care, or something else specific about dogs?\n",
      "I’d be happy to! When you ask **“What’s the population?”** more context helps me give an accurate answer. Population typically refers to the number of people living in a particular place—like a country, city, state, or even a specific community.\n",
      "\n",
      "Here are a few examples of how I could answer:\n",
      "\n",
      "- **Country:** If you asked *What’s the population of Japan?* (As of 2024, about 124 million people.)\n",
      "- **City:** If you asked *What’s the population of New York City?* (As of 2024, about 8.3 million people.)\n",
      "- **World:** If you meant the world, the global population in 2024 is about **8.1 billion**.\n",
      "\n",
      "Population numbers change regularly due to births, deaths, and migration, and official counts often come from government censuses or estimates from organizations like the United Nations.\n",
      "\n",
      "If you tell me the place you’re interested in, I’d be glad to give you the latest available population information!\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, SQLiteSession\n",
    "\n",
    "agent = Agent(name=\"Assistant\")\n",
    "\n",
    "# Different session IDs maintain separate conversation histories\n",
    "result1 = await Runner.run(\n",
    "    agent,\n",
    "    \"What's the population?\",\n",
    "    session=session\n",
    ")\n",
    "\n",
    "# Custom SQLite database file\n",
    "session1 = SQLiteSession(\"user_123\", \"conversations.db\")\n",
    "result2 = await Runner.run(\n",
    "    agent,\n",
    "    \"What's the population?\",\n",
    "    session=session1\n",
    ")\n",
    "\n",
    "result3 = await Runner.run(\n",
    "    agent,\n",
    "    \"What is a dog?\",\n",
    "    session=SQLiteSession(\"user_456\", \"conversations.db\")\n",
    ")\n",
    "\n",
    "result4 = await Runner.run(\n",
    "    agent,\n",
    "    \"Tell me more\",\n",
    "    session=session1\n",
    ")\n",
    "\n",
    "print(result1.final_output)\n",
    "print(result2.final_output)\n",
    "print(result3.final_output)\n",
    "print(result4.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5d521",
   "metadata": {},
   "source": [
    "Custom session implementations\n",
    "You can implement your own session memory by creating a class that follows the Session protocol (i.e. maybe you have a certain way you do your history truncating):\n",
    "\n",
    "## TO DO!!!\n",
    "EXAMPLE IN DOCUMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f62e48",
   "metadata": {},
   "source": [
    "### Adding Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42cb1787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user, John, is 47 years old.\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from agents import Agent, RunContextWrapper, Runner, function_tool\n",
    "\n",
    "@dataclass\n",
    "class UserInfo:  \n",
    "    name: str\n",
    "    uid: int\n",
    "\n",
    "@function_tool\n",
    "async def fetch_user_age(wrapper: RunContextWrapper[UserInfo]) -> str:  \n",
    "    \"\"\"Fetch the age of the user. Call this function to get user's age information.\"\"\"\n",
    "    return f\"The user {wrapper.context.name} is 47 years old\"\n",
    "\n",
    "# Initialize context\n",
    "user_info = UserInfo(name=\"John\", uid=123)\n",
    "\n",
    "agent = Agent[UserInfo](  \n",
    "    name=\"Assistant\",\n",
    "    tools=[fetch_user_age],\n",
    ")\n",
    "\n",
    "result = await Runner.run(  \n",
    "    starting_agent=agent,\n",
    "    input=\"What is the age of the user?\",\n",
    "    context=user_info,\n",
    ")\n",
    "\n",
    "print(result.final_output)  \n",
    "# The user John is 47 years old."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6841b6",
   "metadata": {},
   "source": [
    "## Input Guardrails + agent handoff\n",
    "\n",
    "Guardrails run in parallel to your agents, enabling you to do checks and validations of user input -> This is why if you look at the trace you can see that the agent ran as well but if the tripwire is triggered we don't display the response.\n",
    "\n",
    "Creating an AI Agent Tutor with multiple domain specialities + an input guardrail that only answers questions related to homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ab61131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a structured output format\n",
    "from pydantic import BaseModel\n",
    "from agents import (\n",
    "    Agent,\n",
    "    GuardrailFunctionOutput,\n",
    "    InputGuardrailTripwireTriggered,\n",
    "    RunContextWrapper,\n",
    "    Runner,\n",
    "    TResponseInputItem,\n",
    "    input_guardrail,\n",
    ")\n",
    "import logging\n",
    "\n",
    "class HistoryHomeworkOutput(BaseModel):\n",
    "    is_history_homework: bool\n",
    "    reasoning: str\n",
    "\n",
    "# Create a guardrail agent\n",
    "guardrail_agent = Agent(\n",
    "    name = \"Guardrail Check\",\n",
    "    instructions = \"Check if the user is asking about history homework\",\n",
    "    output_type= HistoryHomeworkOutput\n",
    ")\n",
    "\n",
    "@input_guardrail\n",
    "# Define guardrail function\n",
    "async def history_homework_guardrail(ctx: RunContextWrapper[None], \n",
    "                             agent: Agent,\n",
    "                             input_data: str | list[TResponseInputItem]\n",
    "                             ) -> GuardrailFunctionOutput:\n",
    "    result = await Runner.run(guardrail_agent, input_data, context = ctx.context)\n",
    "    final_output = result.final_output_as(HistoryHomeworkOutput)\n",
    "    logging.info(final_output)\n",
    "\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=final_output,\n",
    "        tripwire_triggered=final_output.is_history_homework\n",
    "    )\n",
    "\n",
    "\n",
    "#### Create specialized agents\n",
    "# Create a science tutor agent\n",
    "science_tutor_agent = Agent(\n",
    "    name = \"Science Tutor\",\n",
    "    handoff_description=\"Specialized agent for scientific questions\",\n",
    "    instructions= \"You provide assistance with scientific queries. Explain science concepts clearly.\"\n",
    ")\n",
    "\n",
    "# Create a math tutor agent\n",
    "math_tutor_agent = Agent(\n",
    "    name = \"Math Tutor\",\n",
    "    handoff_description= \"Specialist agent for math instrucitons\",\n",
    "    instructions = \"You provide help with math problems. Explain your reasoning at each step and include examples.\"\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name = \"Triage Agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the nature of the request\",\n",
    "    handoffs=[science_tutor_agent, math_tutor_agent],\n",
    "    input_guardrails=[history_homework_guardrail],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "719f8b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_history_homework=False reasoning='The user is asking about the chemical nature of water, which is a science (specifically chemistry) question, not about history homework.'\n"
     ]
    }
   ],
   "source": [
    "# Run the individual agent with a query\n",
    "# result = await Runner.run(science_tutor_agent, \"What element is water?\")\n",
    "# print(result.final_output)\n",
    "# result = await Runner.run(math_tutor_agent, \"What is the derivative of x^2 - 1\")\n",
    "# print(result.final_output)\n",
    "\n",
    "# run triage agent\n",
    "# result = await Runner.run(triage_agent, \"What is derivative of x^2 - 1\")\n",
    "# print(result.final_output)\n",
    "\n",
    "result = await Runner.run(guardrail_agent, \"What element is water?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7882a5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water is **not** an element. Water is a **compound** made up of two elements: **hydrogen** and **oxygen**. Its chemical formula is **H₂O**, which means each molecule of water contains two hydrogen atoms and one oxygen atom bonded together.\n",
      "\n",
      "- **Element:** A pure substance made of only one kind of atom (e.g., hydrogen, oxygen, gold).\n",
      "- **Compound:** A substance formed when two or more elements are chemically joined (e.g., water, carbon dioxide).\n",
      "\n",
      "**Summary:**  \n",
      "**Water (H₂O) is a compound, not an element.**\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(triage_agent, \"What element is water?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc620b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked by input guardrail.\n"
     ]
    }
   ],
   "source": [
    "# Test with history question (will trigger guardrail)\n",
    "try:\n",
    "    result = await Runner.run(triage_agent, \"who was the first president of canada?\")\n",
    "    print(result.final_output)\n",
    "except InputGuardrailTripwireTriggered:\n",
    "    print(\"Blocked by input guardrail.\")        # only guardrail trips land here\n",
    "except Exception as e:\n",
    "    print(f\"Error triggered: {type(e).__name__}\") # everything else (timeouts, bugs, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
